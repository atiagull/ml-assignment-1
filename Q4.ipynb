{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e46eb47-78d8-4a5f-ac1e-f89364473b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 : 0.6809961986847383\n",
      "Cost at iteration 500 : 0.31972481138121184\n",
      "Cost at iteration 1000 : 0.3152048650656392\n",
      "Cost at iteration 1500 : 0.3145244462958947\n",
      "Cost at iteration 2000 : 0.31438580468516697\n",
      "Cost at iteration 2500 : 0.3143543237055585\n",
      "Cost at iteration 3000 : 0.3143468311382626\n",
      "Cost at iteration 3500 : 0.31434500822089134\n",
      "Cost at iteration 4000 : 0.3143445599694541\n",
      "Cost at iteration 4500 : 0.3143444491683448\n",
      "Cost at iteration 5000 : 0.3143444217091051\n",
      "Cost at iteration 5500 : 0.3143444148952935\n",
      "Cost at iteration 6000 : 0.31434441320341594\n",
      "Cost at iteration 6500 : 0.3143444127831871\n",
      "Cost at iteration 7000 : 0.31434441267879404\n",
      "Cost at iteration 7500 : 0.31434441265285873\n",
      "Cost at iteration 8000 : 0.31434441264641527\n",
      "Cost at iteration 8500 : 0.3143444126448142\n",
      "Cost at iteration 9000 : 0.3143444126444165\n",
      "Cost at iteration 9500 : 0.3143444126443177\n",
      "weights :  [-2.73847748 32.82464425]\n",
      "Confusion Matrix:\n",
      " [[12  0]\n",
      " [ 4  4]]\n",
      "Accuracy: 0.8\n",
      "Precision: 1.0\n",
      "Recall: 0.5\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('.\\\\Q4-data\\\\trainlr.csv')\n",
    "test_set = pd.read_csv('.\\\\Q4-data\\\\testlr.csv')\n",
    "\n",
    "x_test = np.array(test_set.iloc[:,:-1])\n",
    "y_test = np.array(test_set.iloc[:,2])\n",
    "\n",
    "x_train = np.array(dataset.iloc[:,:-1])\n",
    "y_train = np.array(dataset.iloc[:,2])\n",
    "\n",
    "\n",
    "\n",
    "rows, columns = x_train.shape\n",
    "w = np.zeros(columns)  # 1D array for weights\n",
    "b = 0\n",
    "\n",
    "\n",
    "def y_hat(x_train,i,w,b):\n",
    "    #i is row/example and w is weight vector/series\n",
    "    return sigmoid_regressor(b + w[0]*x_train[i,0] + w[1]*x_train[i,1]) #return 0 or 1 scala\n",
    "    \n",
    "def sigmoid_regressor(z):\n",
    "    return (1/(1+np.exp(-1*z))) #this will return scalar if z is scalar and vector if z is vector\n",
    "\n",
    "def gradient_Descent(x_train, y_train, w, b):\n",
    "    learning_rate = 0.1\n",
    "    n, m = x_train.shape\n",
    "    w_gradient = np.zeros_like(w)  \n",
    "    b_gradient = 0  \n",
    "\n",
    "    # Accumulate gradients\n",
    "    for i in range(n):\n",
    "        hp = y_hat(x_train,i,w,b)\n",
    "        error = (y_train[i] - hp)\n",
    "        w_gradient += -error * x_train[i]  \n",
    "        b_gradient += -error\n",
    "\n",
    "    # Update weights and bias\n",
    "    w = w - learning_rate * w_gradient\n",
    "    b = b - learning_rate * b_gradient\n",
    "    return w, b\n",
    "\n",
    "def cost(x_train, y_train, w,b):\n",
    "    error = 0\n",
    "    n = x_train.shape[0]\n",
    "    for i in range (n):\n",
    "        pv= sigmoid_regressor(b + w[0]*x_train[i,0] + w[1]*x_train[i,1])\n",
    "        error+=((-1)*y_train[i]*np.log(pv) - (1-y_train[i])*np.log(1-pv))\n",
    "    return error/n # sum of errors for all samples \n",
    "\n",
    "\n",
    "for it in range(10000):\n",
    "    w, b = gradient_Descent(x_train, y_train, w, b)\n",
    "    if it % 500 == 0:\n",
    "        err = cost(x_train, y_train, w, b)\n",
    "        print(\"Cost at iteration\", it, \":\", err)\n",
    "\n",
    "\n",
    "print(\"weights : \",  w)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict function for test data\n",
    "def predict(x, w, b):\n",
    "    probabilities = sigmoid_regressor(np.dot(x, w) + b)\n",
    "    return [1 if p >= 0.5 else 0 for p in probabilities]\n",
    "\n",
    "y_pred = predict(x_test, w, b)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4cec3ee-861c-4e4d-a086-b255d3f01f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 : 0.6914739223679884\n",
      "Cost at iteration 500 : 0.40838485211420394\n",
      "Cost at iteration 1000 : 0.35627605310499766\n",
      "Cost at iteration 1500 : 0.33552799926893917\n",
      "Cost at iteration 2000 : 0.32439539685217433\n",
      "Cost at iteration 2500 : 0.3174054489990058\n",
      "Cost at iteration 3000 : 0.31256626069427457\n",
      "Cost at iteration 3500 : 0.30898342380456334\n",
      "Cost at iteration 4000 : 0.30619673614164755\n",
      "Cost at iteration 4500 : 0.30394567898540803\n",
      "Cost at iteration 5000 : 0.30207197253648904\n",
      "Cost at iteration 5500 : 0.30047407274136695\n",
      "Cost at iteration 6000 : 0.29908395459478077\n",
      "Cost at iteration 6500 : 0.29785441298004184\n",
      "Cost at iteration 7000 : 0.2967517155604451\n",
      "Cost at iteration 7500 : 0.29575115107575456\n",
      "Cost at iteration 8000 : 0.29483422552507405\n",
      "Cost at iteration 8500 : 0.2939868371715135\n",
      "Cost at iteration 9000 : 0.29319805456484527\n",
      "Cost at iteration 9500 : 0.2924592779634517\n",
      "Final weights: [-1.37594519 23.67075062 12.16864857  0.42930158 15.01432918]\n",
      "Final bias: -6.487039157789972\n",
      "Confusion Matrix:\n",
      " [[11  1]\n",
      " [ 4  4]]\n",
      "Accuracy: 0.75\n",
      "Precision: 0.8\n",
      "Recall: 0.5\n",
      "F1 Score: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "#part b using non_linear decision boundary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "train_set = pd.read_csv('.\\\\Q4-data\\\\trainlr.csv')\n",
    "test_set = pd.read_csv('.\\\\Q4-data\\\\testlr.csv')\n",
    "\n",
    "x_train = np.array(train_set.iloc[:, :-1])\n",
    "y_train = np.array(train_set.iloc[:, 2])\n",
    "x_test = np.array(test_set.iloc[:, :-1])\n",
    "y_test = np.array(test_set.iloc[:, 2])\n",
    "\n",
    "# Add polynomial features up to degree 2\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_test_poly = poly.transform(x_test)\n",
    "\n",
    "# Initialize parameters\n",
    "rows, columns = x_train_poly.shape\n",
    "w = np.zeros(columns)  # 1D array for weights with new polynomial features\n",
    "b = 0\n",
    "\n",
    "def sigmoid_regressor(z):\n",
    "    return 1 / (1 + np.exp(-z))  # sigmoid function\n",
    "\n",
    "def y_hat(x_train, i, w, b):\n",
    "    return sigmoid_regressor(np.dot(x_train[i], w) + b)  # return scalar probability for i-th sample\n",
    "\n",
    "def gradient_Descent(x_train, y_train, w, b, learning_rate=0.01):\n",
    "    n, m = x_train.shape\n",
    "    w_gradient = np.zeros_like(w)\n",
    "    b_gradient = 0\n",
    "\n",
    "    # Accumulate gradients\n",
    "    for i in range(n):\n",
    "        hp = y_hat(x_train, i, w, b)\n",
    "        error = (y_train[i] - hp)\n",
    "        w_gradient += -error * x_train[i]\n",
    "        b_gradient += -error\n",
    "\n",
    "    # Update weights and bias\n",
    "    w -= learning_rate * w_gradient\n",
    "    b -= learning_rate * b_gradient\n",
    "    return w, b\n",
    "\n",
    "def cost(x_train, y_train, w, b):\n",
    "    error = 0\n",
    "    n = x_train.shape[0]\n",
    "    for i in range(n):\n",
    "        pv = y_hat(x_train, i, w, b)\n",
    "        error += -y_train[i] * np.log(pv) - (1 - y_train[i]) * np.log(1 - pv)\n",
    "    return error / n  # average error for better interpretability\n",
    "\n",
    "# Training loop\n",
    "for it in range(10000):\n",
    "    w, b = gradient_Descent(x_train_poly, y_train, w, b)\n",
    "    if it % 500 == 0:\n",
    "        err = cost(x_train_poly, y_train, w, b)\n",
    "        print(\"Cost at iteration\", it, \":\", err)\n",
    "\n",
    "print(\"Final weights:\", w)\n",
    "print(\"Final bias:\", b)\n",
    "\n",
    "# Predict function for test data\n",
    "def predict(x, w, b):\n",
    "    probabilities = sigmoid_regressor(np.dot(x, w) + b)\n",
    "    return [1 if p >= 0.5 else 0 for p in probabilities]\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = predict(x_test_poly, w, b)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114a53e-16ab-4332-a692-b41a8b6f7f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
